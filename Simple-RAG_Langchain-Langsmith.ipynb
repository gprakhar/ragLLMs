{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "collapsed": true,
        "id": "Jk8J58s2fctr"
      },
      "outputs": [],
      "source": [
        "!pip install --quiet --upgrade langchain langchain-community langchain-chroma langchain-text-splitters langchain-google-vertexai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import getpass\n",
        "import os\n",
        "\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\"\n",
        "os.environ[\"LANGCHAIN_API_KEY\"] = \"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\"\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = \"default\""
      ],
      "metadata": {
        "id": "2d3g9M31_p4x"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(os.environ[\"LANGCHAIN_PROJECT\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Cp7a77BUXKs",
        "outputId": "b8dd3641-ad69-498d-fc04-8f62e25614b6"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "default\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "PROJECT_ID = \"test-rag-sep2024\"\n",
        "REGION = \"us-central1\"\n",
        "\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "metadata": {
        "id": "IuQAB5gddzYz"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import vertexai\n",
        "vertexai.init(project = PROJECT_ID , location = REGION)"
      ],
      "metadata": {
        "id": "4g6CmfMWiGcn"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_google_vertexai import ChatVertexAI\n",
        "\n",
        "llm = ChatVertexAI(model=\"gemini-1.5-flash\")"
      ],
      "metadata": {
        "id": "Op4eqd_zhyTh"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import bs4\n",
        "from langchain import hub\n",
        "from langchain_chroma import Chroma\n",
        "from langchain_community.document_loaders import WebBaseLoader\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langchain_google_vertexai import VertexAIEmbeddings\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SanB02qsq7-_",
        "outputId": "162ecd64-550d-40fd-a845-9f216d124396"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:langchain_community.utils.user_agent:USER_AGENT environment variable not set, consider setting it to identify your requests.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Load, chunk and index the contents of the blog.\n",
        "loader = WebBaseLoader(\n",
        "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
        "    bs_kwargs=dict(\n",
        "        parse_only=bs4.SoupStrainer(\n",
        "            class_=(\"post-content\", \"post-title\", \"post-header\")\n",
        "        )\n",
        "    ),\n",
        ")\n",
        "docs = loader.load()"
      ],
      "metadata": {
        "id": "nVW1RYpHrkDj"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
        "splits = text_splitter.split_documents(docs)\n",
        "\n",
        "embeddings = VertexAIEmbeddings(model_name=\"text-embedding-004\")\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "c-BHZY6grm5D"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore = Chroma.from_documents(documents=splits, embedding=embeddings)"
      ],
      "metadata": {
        "id": "lSp0_LHu9uyR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Retrieve and generate using the relevant snippets of the blog.\n",
        "retriever = vectorstore.as_retriever()\n",
        "prompt = hub.pull(\"rlm/rag-prompt\")"
      ],
      "metadata": {
        "id": "9JmXDnYwrrHp"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def format_docs(docs):\n",
        "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
      ],
      "metadata": {
        "id": "o0wGPcUuruTS"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain = (\n",
        "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
        "    | prompt\n",
        "    | llm\n",
        "    | StrOutputParser()\n",
        ")"
      ],
      "metadata": {
        "id": "XglA_4hNrxD3"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rag_chain.invoke(\"Describe how LLM agents work using chain of thought?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "JkNPET8Ur2bl",
        "outputId": "7a496db3-8845-4f60-a597-fa47645c33d8"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'LLM agents leverage chain of thought (CoT) to break down complex tasks into smaller, manageable steps. This allows the model to \"think step by step\" and use more computational resources during task execution. By decomposing large tasks, CoT aids in interpreting the model\\'s reasoning process. \\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    }
  ]
}